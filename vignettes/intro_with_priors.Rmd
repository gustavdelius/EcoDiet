---
title: "How to use EcoDiet with stomachal data, isotopic data and priors from the literature"
author: "Heloise Thero"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to use EcoDiet with stomachal data, isotopic data and priors from the literature}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The goal of EcoDiet is to combine biotracers and stomach content analyses together with *a priori* knowledge from the literature to simulataneously identify who eats whom in the food web (**topology matrix**), and in which proportions (**diet matrix**). 

More specifically, EcoDiet is an integrated Bayesian model that uses *(i)* stomach content analyses and priors from studies found in the literature to estimate the probability that any trophic link exists *(ii)* biotracers analyses and priors from studies found in the literature to estimate the dietary proportions of each consumer in the food web conditionnally to the trophic links identified.

There are two ways of using this package:

* *Default option* - Only stomach content and biotracers data are integrated, and non informative priors will be used;

* Stomach content and biotracers data are integrated and results from a literature search are used to formulate informative priors. 

In this vignette, we present and detail the second option.

Note that biotracers data will be here illustrated by bulk stable isotope only, but EcoDiet could be used to treat other analyses such as fatty acids or specific-compounds stable isotopes.


## Load the package

The first thing to do is to load the EcoDiet package.

```{r}
library(EcoDiet)
```

EcoDiet requires the installation of JAGS (see [the README](https://github.com/heloisethero/EcoDiet/blob/master/README.md) if you have an error).

## Load and check your data

Then, you need to load the data you want to be analyzed by EcoDiet. You can load your data by importing it from `.csv` files. To be treated by the package, your data should be in specific formats, similar to those of following examples.

* Isotopic data:

```{r}
example_isotope_data_path <- system.file("extdata", "example_isotope_data.csv",
                                    package = "EcoDiet")
example_isotope_data <- read.csv(example_isotope_data_path)
knitr::kable(example_isotope_data)
```

Each line of the table represents one individual on which were conducted stable isotope analyses. For a given individual, stable isotope analyses can be realized for various elements (carbon and nitrogen in this example). The first column of the table indicates to which trophic group the individual belongs and the others contain the isotopic measurements.

* Stomachal data:

```{r}
example_stomach_data_path <- system.file("extdata", "example_stomach_data.csv",
                                    package = "EcoDiet")
example_stomach_data <- read.csv(example_stomach_data_path)
knitr::kable(example_stomach_data)
```

The stomach content table gathers the sum of occurrences of each prey type in the stomachs of trophic groups. The first column of the table contains the names of the prey and the headers of the following columns contain the names of **all** trophic groups with or without stomach content analyses available: in the case where no analyses were available, as for groups at the base of the trophic network, a column filled with zeros must be provided. 

The last row of the table indicates how many (non-empty) stomachs have been analyzed for each trophic group. 
In this example, for the "huge" animals, 19 stomachs were analyzed and contained remainings. Among these stomachs, 17 contain "Large" animal remainings and 12 contain "medium" animal remainings.

* Diet matrix from the literature:

```{r}
example_literature_diets_path <- system.file("extdata", "example_literature_diets.csv",
                                    package = "EcoDiet")
example_literature_diets <- read.csv(example_literature_diets_path)
knitr::kable(example_literature_diets)
```

This table is a diet matrix built from a literature search. As for the stomach contents table, all trophic groups must be included and there should be as many columns as rows as number of trophic groups. The matrix coefficients are the contributions (in decimals) of the corresponding row-group to the diet of the corresponding column-group averaged over the selected studies. The coefficients within a given column must sum to 1, except if the column corresponds to a group at the base of the trophic network.  In this example, the selected studies identified that "huge" animals eat equally "large" and "medium" animals (thus the 0.5 and 0.5 numbers in the first column). The "small" animals are at the base of the ecosystem and their prey are not considered in the food-web representation.

These priors will be used to formulate:

1. The priors on the probabilities that links exist. Whether they are null or strictly positive, the coefficients of the diet matrix from the literature are used to respectively shift toward 0 or 1 the Beta distributions used as priors on the varaibles "eta".

2. The priors on dietary proportions. The coefficients of the diet matrix from the literature are entered as the hyperparameters "alpha" of the Dirichlet distributions for the priors on the variables "PI".


* the `literature_pedigrees` parameters. Because the relevance of the literature information is variable, you could be willing to modulate the precision of the derived priors on "eta" and "PI" according to the reliability of this information. To do so, you need to enter a Pedigree score for each consumer. This Pedigree score ranks from 0 to 1 and quantifies the relevance of the information found about a given consumer. Ideally the information on the diets is extracted from studies recently conducted in the same area. But when local and recent data information is missing, it can also come from foreign areas or older periods with eventually different ecosystem structure and functioning, hence less pertinent regarding the case-study. You can down-weight the importance of these priors by setting a low pedigree score for this predator. You need to enter a pedigree score (a number between 0 to 1) for each predator. If you want to give each study an equal importance, you can see all the pedigrees to 1 by default.

```{r}
example_literature_pedigrees_path <- system.file("extdata", "example_literature_pedigrees.csv",
                                    package = "EcoDiet")
example_literature_pedigrees <- read.csv(example_literature_pedigrees_path)
knitr::kable(example_literature_pedigrees)
```

Here the dietary proportions from the literature are estimated very reliable for the "huge" animals, so the pedigree score associated is high (0.9). On the contrary, the diet proportions for the "medium" animals come from an old article focusing on a very different ecosystem so the pedigree score associated is low (0.2). Because the "small" animals are at the base of the ecosystem and its diet proportions won't be estimated, its pedigree score will not be used so we have put the by-default value (1).

The Pedigree score is used to calculate the hyperparameters of the probability distributions used to formulate "eta" and "PI" priors.

## Plot the data

You can visualize your data with the `plot_data` function:

```{r, fig1, fig.height = 4, fig.width = 6, fig.align = "center"}
plot_data(isotope_data = example_isotope_data,
          stomach_data = example_stomach_data,
          literature_diets = example_literature_diets)
```

## Preprocess the data

* You first need to have loaded your `.csv` files as shown previously. 

If you have your files in a `data` folder and in a specific `.csv` format (semicolon separated, and not coma separated), you should add the `data` folder in the path and use the `sep` argument to load your data:
```{r, eval = FALSE}
example_stomach_data     <- read.csv("./data/my_stomach_data.csv",     sep = ";")
example_isotope_data     <- read.csv("./data/my_isotope_data.csv",     sep = ";")
example_literature_diets <- read.csv("./data/my_literature_diets.csv", sep = ";")
```

* You need to define the trophic enrichment factors that corresponds to your isotopic data. If your isotopic data files contains d13C and d15N data as in the example, then you should enter the trophic enrichment factors for the d13C and d15N isotopes (in that order):
```{r, eval = FALSE}
trophic_enrichment_factor = c(0.8, 3.4)
```

* You also need to precise that you will use priors from the literature in the model:
```{r, eval = FALSE}
literature_prior = TRUE
```

* The `preprocess_data` function then checks and rearranges the data in a specific format so that the EcoDiet model can be run:
```{r, eval = FALSE}
data <- preprocess_data(isotope_data = example_isotope_data,
                        trophic_enrichment_factor = c(0.8, 3.4),
                        literature_prior = TRUE,
                        stomach_data = example_stomach_data,
                        literature_diets = example_literature_diets)
```

If any error appears, it means your data is not in the correct format. Please read the error message and try to rearrange the data in the correct format.

## Check the trophic links matrix

The last message tells you to check the trophic links that will be investigated by the model. It is generally not wise to assume that all the trophic links are possible ( = a matrix filled with only ones), as the model will likely be over-paramaterized and have problems to converge. You therefore need to keep only the reasonnable trophic links (e.g., a shrimp cannot eat a whale).

The matrix displayed by the `preprocess_data` function is based on the stomach content data and the literature diets: by-default, EcoDiet will investigate trophic links only if you have identified them as plausible regarding your literature search or what you have found in stomachs analyses. If you want to add another trophic link, you can modify the literature diets to add a small number for the prey-predator couple for which you want to add a trophic link.

For example if you know that the "huge" animals can exceptionnally eat "small" animals, even if it is not mentionned in the literature, you can modify the literature diets matrix this way:
```{r}
example_literature_diets[3, 2] <- 0.02
example_literature_diets[1, 2] <- 0.49
example_literature_diets[4, 2] <- 0.49
knitr::kable(example_literature_diets)
```

Now you can see that the new trophic links matrix will be investigated by the model:
```{r, eval = FALSE}
data <- preprocess_data(isotope_data = example_isotope_data,
                        trophic_enrichment_factor = c(0.8, 3.4),
                        literature_prior = TRUE,
                        stomach_data = example_stomach_data,
                        literature_diets = example_literature_diets)
```

## Parameterizing the relative influence of the literature information relative to data

The calculation of the priors for the variables "eta" and "PI" from the literature values and the Pedigree scrore also involved two parameters allowing to modulate the relationship between the Pedigree value and the priors' precision.

* the `nb_literature` parameter. This parameter is used to formulate the prior on the "eta" parameters and is set by the user according to its study case. `nb_literature` is an integer equivalent to a number of stomachs sampled and, in a way, represents the number of stomachs that the user judges ideal to infer on a species' diet; in other words the number of stomachs that would be equivalent to a quantitative dietary study from the literature both locally and recently conducted following a good sampling scheme (i.e., of Pedigree 1).

For a given consumer, the ratio between the product `nb_literature * literature_pedigrees` and the number of stomachs determines the influence of the literature relative to data. Thus, the higher the `nb_literature` is, the stronger will be the weight of the literature in the final inferences. In practice, due to the inherent emptiness of stomachs when analyzing them, `nb_literature` should be set at a lower value in order to not put too much weight to the literature. . Setting this parameter to 10 is like saying that the prior from the literature will weight as much as additional data from 10 stomachs. There are no rules for attributing a value to `nb_literature`, but a good start can be the mean number of stomachs analyzed per species in the data.

```{r}
nb_literature = 10
```


* the `literature_slope` parameter. This parameter is a number between 0 and 1 (excluding 0) used to calculate the hyperparameters of the Dirichlet priors for the PI parameter. To represent the greater uncertainty around dietary proportions from the literature when they come from a less relevant study, we fixed the hyperparameters so that their mean coefficient of variation increases with decreasing `literature_pedigrees`. This linear relationship is defined by an intercept giving a coefficient of variation of 1 for a null `literature_pedigrees`, and by a slope equal to `literature_slope`. Thus, increasing the`literature_slope` value tends to make the literature prior on dietary proportions stronger. This value is set by the user to adapt to specific cases, e.g. the number of biotracers used in the study etc. By default it is equal to 0.5.

```{r}
literature_slope = 0.5
```


You can set different values for these parameters with the `preprocess_data` function:

```{r}
data <- preprocess_data(isotope_data = example_isotope_data,
                        trophic_enrichment_factor = c(0.8, 3.4),
                        literature_prior = TRUE,
                        stomach_data = example_stomach_data,
                        literature_diets = example_literature_diets,
                        literature_pedigrees = example_literature_pedigrees,
                        nb_literature = 10,
                        literature_slope = 0.5)
```


## Write the model

The `write_model` function writes the model in the BUGS syntax. The option non informative priors / informative priors must be specified again at this level. 

```{r}
model_string <- write_model(literature_prior = TRUE)
```

## Run the model

Now that the model is defined, you can use the function `run_model` to run the model. By default the number of MCMC iterations is very low (1,000), it allows you to test if your model is compiling properly. In most of the cases, this low number of iterations is not sufficient to achieve a satisfactory model convergence (as you can see from the warning message):

```{r}
mcmc_output <- run_model(textConnection(model_string), data)
```

We advise you to increase the number of iterations until you have met the convergence threshold:

```{r, eval = FALSE}
mcmc_output <- run_model(textConnection(model_string), data, nb_iter = 1e6)
```

If you see again a warning message being printed, you should follow the advices of the corresponding vignette: `vignette("model_warnings")`.

## Plot and save the model's mean results

In Bayesian models, the parameters are represented by their probability distributions. So here the model's outputs are the approximated probability distributions for the diet propotions (PI) and the trophic links probabilities (eta). To summarize these distributions, we can use point estimates like the mean and visualize it with the `plot_results` function:

```{r, fig2, fig.height = 4, fig.width = 6, fig.align = "center"}
plot_results(mcmc_output, data)
```

The means are automatically saved when running this function so you can access them and save them as `.csv` tables:

```{r, eval = FALSE}
load("PI_mean.Rdata")
write.table(PI_mean,  file = "PI_mean.csv",  sep = ",", col.names = NA)

load("eta_mean.Rdata")
write.table(eta_mean, file = "eta_mean.csv", sep = ",", col.names = NA)
```

## Plot the probability densities

You can also plot the probability densities for the `PI` variable and for one predator:

```{r, fig3, fig.height = 4, fig.width = 6, fig.align = "center"}
plot_results(mcmc_output, data, variables = "PI", pred = "huge")
```

If you find the plot to contain too much information, you can also precise for which predator you want to see the probability density:

```{r, fig4, fig.height = 4, fig.width = 6, fig.align = "center"}
plot_results(mcmc_output, data, variables = "PI", pred = "huge", prey = "large")
```

## Save the full results

The model's full results are automatically saved in a file named `mcmc_ouput` so you can access them using:

```{r}
load("mcmc_output.Rdata")
mcmc_output <- signif(mcmc_output, digits = 2)
knitr::kable(head(mcmc_output))
```

You can now compute any summary statistics that you need, on top of the mean. For example if you want the median (thus the 50% quantile), and the 5% and the 95% quantiles of your distribution, you can use:

```{r}
quantiles <- apply(mcmc_output, 2, function(X) quantile(X, probs = c(0.05, 0.5, 0.95)))
quantiles <- signif(quantiles, digits = 2)
knitr::kable(quantiles)
```

The quantiles can finally be saved as `.csv` tables:
```{r, eval = FALSE}
write.table(quantiles, file = "quantiles.csv", sep = ",", col.names = NA)
```

## Plot the prior distributions

You can also plot the prior distributions by running the model with empty data. To do so, you can use the following instructions:

```{r, fig5, fig.height = 4, fig.width = 6, fig.align = "center"}
data$o[] <- NA
data$y[] <- NA
data$nb_y[] <- 0

mcmc_priors <- run_model(textConnection(model_string), data,
                         nb_adapt = 1e2, nb_burnin = 1, nb_iter = 1e5)

plot_results(mcmc_priors, data, variables = "PI", pred = "huge")
```

## Save another variable than PI and eta

You have the possibility to access to the model's other parameters if you wish.

For example you may be interested by the variable `delta` that represents the trophic enrichment factor. In the EcoDiet model, a different trophic enrichment factor is used for each trophic group and for each element, allowing some differences between species. We can save these parameters using the `variables_to_save` argument:

```{r}
mcmc_output <- run_model(textConnection(model_string), data,
                         variables_to_save = c("delta"))
```

And now you can access its mean value using:

```{r}
print(colMeans(mcmc_output))
```

## Environment on which this vignette has been run

```{r}
devtools::session_info()
```
